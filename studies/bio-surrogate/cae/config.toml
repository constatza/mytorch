[mlflow]
experiment_name = "test artifacts 1"
run_name = "basic cae"
log_models = false

[mlflow.server]
host = "localhost"
port = 5000
backend_store_uri = "sqlite:///M:/constantinos/data/bio/5-equations/mlruns/mlflow.db"
default_artifact_root = "file:///M:/constantinos/data/bio/5-equations/mlruns"
tracking_uri = "https://{mlflow.server.host}:{mlflow.server.port}"


[optuna]
n_trials = 200
direction = "minimize"

[trainer]
max_epochs = 400
enable_checkpointing = false
logger = false
fast_dev_run = true

[model]
name = "caes.cae1d.BasicCAE"
latent_size = {low = 3, high = 15, type = "int"}
kernel_size = {low = 3, high = 11, type = "int", step = 2}
num_layers = {low = 1, high = 6, type = "int"}
reduced_channels = { low = 200, high = 600, type = "int" }
reduced_timesteps =  {low = 200, high = 600, type = "int" }

[optimizer]
name = "RAdam"
lr = 0.001  # Range
min_lr = 1e-7

[scheduler]
name = "ReduceLROnPlateau"
factor = 0.6
patience = 10
min_lr = 1e-7

[pruner]
name = "MedianPruner"
n_startup_trials = 10
interval_steps = 10

[transforms]
features = [
    {name = "NumpyToTensor"},
    {name = "MinMaxScaler", dim = [0, -1]}
]

# Sampler configuration for hyperparameter search
[sampler]
name = "TPESampler"  # Example of using a sampler

[datamodule]
name = "FileDataModule"
test_size = 0.3
batch_size = 64

[dataloader]
num_workers = 1
persistent_workers = true

[paths]
dataroot = "M:/constantinos/data/bio/5-equations/"
features = "{paths.input}/solutions.npy"
input = "{paths.dataroot}/input/"
output = "{paths.dataroot}/output/"
figures = "{paths.output}/figures/"
latent = "{paths.output}/latent.npy"
predictions = "{paths.output}/predictions.npy"
parameters = "{paths.input}/parameters.npy"





